<!doctype html>
<html lang="en">
  <head>
	<meta name="generator" content="Hugo 0.137.1"><script src="/~sttruong/avs/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=~sttruong/avs/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
<title>Accelerate Virtual Screening with Amortized Neural Search and Multi-Objective Bayesian Optimization</title>


<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><link rel="stylesheet" href="/~sttruong/avs/reveal-js/dist/reset.css">
<link rel="stylesheet" href="/~sttruong/avs/reveal-js/dist/reveal.css"><link rel="stylesheet" href="/~sttruong/avs/css/serif.css" id="theme"><link rel="stylesheet" href="/~sttruong/avs/highlight-js/default.min.css">
  </head>
  <body>
    
    <div class="reveal">
      <div class="slides">
  

    
<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<!-- ### Accelerate Virtual Screening 
### with Amortized Neural Search 
### and Prefential Bayesian Optimization -->
<h3 id="accelerate-virtual-screening-in-drug-discovery">Accelerate Virtual Screening in Drug Discovery</h3>
<h3 id="with-neural-diffusion-search">with Neural Diffusion Search</h3>
<div style="display: flex; justify-content: space-between; width: 30%;">
  <img src="images/rhf.png" alt="Third Logo" style="height: 85px; margin-left: 0px; margin-top: 200px">
  <img src="images/SOM_vert_Web_Color_LG.png" alt="Main Logo" style="height: 85px; margin-left: 50px; margin-top: 200px"> 
  <img src="images/sail-logo.jpg" alt="Second Logo" style="height: 85px; margin-left: 85px; margin-top: 200px">
</div>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="outline">Outline</h3>
<ul>
<li>Protein-ligand docking with Diffusion Models</li>
<li>Active Virtual Screening</li>
<li>Incorporating Chemical Intuition</li>
</ul>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="overview">Overview</h3>
<!-- 

<span class='fragment ' ><p>&ndash;&gt;</p>
<!-- <figure style="text-align: center; margin-top: -20px; position: relative;">
  <img src="images/overview.png" alt="Docking Results" style="width: 50%; max-width: 1000px;">
  <div style="position: absolute; bottom: 0; left: 0; width: 100%; height: 38%; background: white;" class="fragment fade-out"></div>
</figure>
</span>

 -->
<figure style="text-align: center; margin-top: -30px; position: relative;">
    <img src="images/overview.png" alt="Overview Image" style="width: 55%; max-width: 1000px;">
  <div style="position: absolute; bottom: 0; left: 0; width: 100%; height: 73%; background: white;" class="fragment fade-out"></div>
  <div style="position: absolute; bottom: 0; left: 0; width: 100%; height: 38%; background: white;" class="fragment fade-out"></div>
</figure>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="overview-streamlining-virtual-screening-with-advanced-techniques">Overview: Streamlining Virtual Screening with Advanced Techniques</h3>
<div style="margin-top: 20px; display: flex; justify-content: space-between; align-items: flex-start;">
  <div style="width: 50%;">
    <h3 style="font-size: 36px;">Challenges:</h3>
    <ol style="font-size: 32px;">
      <li class="fragment" data-fragment-index="1"><b>Training efficient docking models</b> with limited resources.</li>
      <li class="fragment" data-fragment-index="2"><b>Conducting virtual screening</b> within budget constraints.</li>
      <li class="fragment" data-fragment-index="3"><b>Incorporating multiple objectives</b> beyond affinity.</li>
    </ol>
  </div>
  <div style="width: 50%;">
    <h3 style="font-size: 36px; padding-left: 30px;">Solutions:</h3>
    <ol style="font-size: 32px; padding-left: 30px;">
      <li class="fragment" data-fragment-index="1">Enhance docking model through diffusion model.</li>
      <li class="fragment" data-fragment-index="2">Optimize ligand selection through active screening.</li>
      <li class="fragment" data-fragment-index="3">Utilize a neural search engine for multi-objective screening.</li>
    </ol>
  </div>
</div>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="outline-1">Outline</h3>
<ul>
<li>Protein-ligand docking with Diffusion Models</li>
<li><span style="opacity: 0.5;">Active Virtual Screening</span></li>
<li><span style="opacity: 0.5;">Incorporating Chemical Intuition</span></li>
</ul>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="1-diffusion-model-noise-to-pattern">1. Diffusion Model: Noise to pattern</h3>


<span class='fragment ' ><strong>Diffusion models</strong> are a type of machine learning model used to generate data by starting with noise and gradually creating a meaningful pattern.</span>




<span class='fragment ' ><figure style="display: flex; flex-direction: column; align-items: center; width: 80%; margin-left: 80px;"> 
  <img src="images/cat.webp" alt="Diffusion Process" style="width: 30%;"> 
  <figcaption style="text-align: center; font-size: 24px; margin-top: 10px;">Transforming noise into meaningful structures.</figcaption> 
</figure> 
</span>


</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="1-diffusion-model-why-used-for-docking">1. Diffusion Model: Why used for docking?</h3>
<p>Why Use Diffusion Models for Molecules?</p>


<span class='fragment ' ><figure style="display: flex; flex-direction: column; align-items: center; width: 100%; margin-top: 0px;">
  <img src="images/molecular_diffusion.png" alt="Molecular Diffusion Process" style="width: 100%;">
  <figcaption style="text-align: center; font-size: 24px; margin-top: 0px;">From random points to a structured 3D molecule.</figcaption>
</figure>
</span>


</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="1-diffusion-model-training-data">1. Diffusion Model: Training Data</h3>


<span class='fragment ' ><p>The PDB database is limited:</p>
<ul>
<li>Contains only ~17,000 protein-ligand pairs.</li>
<li>Features around 5,000 unique proteins.</li>
</ul>
</span>




<span class='fragment ' ><p>For robust diffusion model training, millions of diverse data points are needed. Data augmentation enhances:</p>
<ul>
<li><strong>Ligand Diversity</strong>: Broader chemical structure and property range.</li>
<li><strong>Protein Diversity</strong>: Wider variety of binding sites for better model generalization.</li>
</ul>
</span>




<span class='fragment ' ><p>Data augmentation techniques create a richer dataset, boosting model performance.</p>
</span>


</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="1-diffusion-model-training-data-1">1. Diffusion Model: Training Data</h3>


<span class='fragment ' ><p><strong>Data Augmentation Techniques</strong>:</p>
<ul style="font-size: 26px"> 
    <li class="fragment"><b>Molecular Dynamics:</b> Employed 59,330 dynamic frames of 14,387 protein-ligand complexes to model ligand flexibility, amounting to 75K training data.</li> 
    <li class="fragment"><b>Data Crawling:</b> Curated 322K protein-ligand complexes, yielding 80K unique proteins.</li>
    <li class="fragment"><b>Pharmacophore Alignment:</b> Generated up to 11M pharmacophore-consistent ligand pairs, significantly expanding the ligand training data.</li> 
</ul> 
</span>




<span class='fragment ' ><div style="display: flex; justify-content: space-between; margin-top: 20px;">
    <div style="width: 49%;">
        <img src="images/md1.gif" alt="MD Simulation Example" style="width: 55%; height: auto; margin-left: 100px; margin-top: -20px;">
        <p style="text-align: center; font-size: 20px; margin-left: -130px; margin-top: -40px;">Figure 1: MD Simulation Trajectories</p>
    </div>
    <div style="width: 49%;">
        <img src="images/pharmacophore.png" alt="Pharmacophore Model Example" style="width: 80%; height: auto;">
        <p style="text-align: center; font-size: 20px; margin-top: 80px;">Figure 2: Pharmacophore Modeling</p>
    </div>
</div>
</span>


</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="1-diffusion-model-results">1. Diffusion Model: Results</h3>
<p><strong>Benchmark on Posebusters Dataset</strong>:


<span class='fragment ' >Posebusters: Version 1 (428 structures) and Version 2 (308 structures), released post-2021 in PDB.</span>




<span class='fragment ' >Performance: % of ligand pairs with $RMSD &lt; 2 Ã…$ in pocket alignment.</span>

</p>


<span class='fragment ' ><figure style="text-align: center; margin-top: -20px; position: relative;">
  <img src="images/docking_results.png" alt="Docking Results" style="width: 100%; max-width: 1000px;">
  <div style="position: absolute; bottom: 0; left: 0; width: 100%; height: 36%; background: white;" class="fragment fade-out"></div>
</figure>
</span>


</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="1-diffusion-model-results-1">1. Diffusion Model: Results</h3>
<p><strong>Benchmark on Posebusters Dataset</strong>:


<span class='fragment ' ><figure style="text-align: center; margin-top: -20px;">
  <img src="images/docking_results.png" alt="Docking Results" style="width: 100%; max-width: 1000px;">
</figure>
</span>

</p>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="1-diffusion-model-neural-search-for-docking">1. Diffusion Model: Neural Search for Docking</h3>


<span class='fragment ' ><p>Traditional docking tools are slow, limiting the efficiency of application of virtual screening.</p>
</span>


<ul> 
  <li class="fragment"><b>Traditional Tools</b> (e.g., Glide, Smina): ~15mins per pose</li> 
  <li class="fragment"><b>Chai</b> (AlphaFold3-like): ~2 mins for 5 poses (7.5x faster)</li> 
  <li class="fragment"><b>Our Diffusion Model</b>: ~5s for 64 poses (180x faster)</li> 
</ul>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="1-diffusion-model-improve-speed-with-local-docking">1. Diffusion Model: Improve Speed with Local Docking</h3>


<span class='fragment ' >Our approach works with both blind and local docking, with local docking being 2.5x faster than blind docking and 450x faster than Glide while still retanining accuracy.</span>




<span class='fragment ' ><figure style="display: flex; flex-direction: column; align-items: center;">
  <div style="display: flex; justify-content: center; width: 100%; gap: 200px;">
      <img src="images/blind.gif" style="width: 40%; margin-right: 10px;" alt="Blind Docking">
      <img src="images/local.gif" style="width: 40%;" alt="Local Docking">
  </div>
  <figcaption style="text-align: center; font-size: 20px; margin-top: 0px;">Blind Docking (left) vs. Local Docking (right) (using 1SYN structure)</figcaption>
</figure>
</span>


</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="1-diffusion-model-next-steps">1. Diffusion Model: Next steps</h3>
<ul>
  <li class="fragment"> Improve on performance of diffusion model to reach SOTA level (i.e finetuninig AlphaFold3 variants)</li>
</ul>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="outline-2">Outline</h3>
<ul>
<li><span style="opacity: 0.5;">Protein-ligand docking with Diffusion Models</span></li>
<li>Active Virtual Screening</li>
<li><span style="opacity: 0.5;">Incorporating Chemical Intuition</span></li>
</ul>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="2virtual-screening-overview">2.Virtual Screening: Overview</h3>
<p>For <strong>a given protein</strong> linked to a certain disease,


<span class='fragment ' >the goal of virtual screening is to select a <strong>few</strong> small molecules (i.e., ligand)</span>




<span class='fragment ' >from a library of <strong>millions</strong> candidates</span>




<span class='fragment ' >such that the selected candidate will have the <strong>highest utility</strong> in disease treating.</span>

</p>


<span class='fragment ' ><figure style="display: flex; flex-direction: column; align-items: center; width: 90%; margin-top: 0px; margin-left: 60px">
<img src="images/vs.png">
</span>


</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="3-active-virtual-screening">3. Active Virtual Screening</h3>
<p>

<span class='fragment ' >Even with the right trade-off objective elicited from expert, exhaustively screening millions of candidate from the virtual screening library is practically infeasible.</span>




<span class='fragment ' >To address this problem, we can choose to screen ligand that looks promising, while avoid ligand that are highly certain to be a bad candidate.</span>

</p>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="3-active-virtual-screening-1">3. Active Virtual Screening</h3>
<p>

<span class='fragment ' >To prioritize high-potential ligands, we use <strong>Bayesian Optimization</strong>,</span>




<span class='fragment ' >an approach that balances exploring new candidates and exploiting known promising ones to efficiently find optimal solutions.</span>

</p>
<ul>
  <li class="fragment">Surrogate model: Gaussian Process, Neural Net, Random forest</li>
  <li class="fragment">Acquisition function: UCB, Greedy, Thompson sampling</li>
</ul>


<span class='fragment ' ><img src="images/avs1.png" alt="Active Virtual Screening Diagram" style="display: block; margin: 0 auto; width: 65%;" class="fragment">
</span>


</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="3-active-virtual-screening-contrained-settings">3. Active Virtual Screening: Contrained settings</h3>
<p>

<span class='fragment ' >In virtual screening, our goal is to find effective ligands efficiently. Traditional methods can be slow, especially with large, diverse libraries.</span>




<span class='fragment ' >If identified ligands are too structurally unique, they may be difficult or impossible to synthesize for chemists.</span>




<span class='fragment ' >By using <strong>constrained settings</strong>, we can focus on ligands with desirable features that are also more likely to be synthetically accessible.</span>

</p>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="3-active-virtual-screening-contrained-settings-1">3. Active Virtual Screening: Contrained settings</h3>
<p>

<span class='fragment ' >Using constrained settings, we can limit our search to clusters of chemically similar ligands,</span>




<span class='fragment ' >increasing the speed and accuracy of our screening while reducing computational demands.</span>

</p>


<span class='fragment ' ><figure style="text-align: center;">
  <img src="images/similarity.png" alt="PCA-Based Virtual Screening" width="40%">
  <figcaption style="font-size: 20px">
    PC1 and PC2 calculated from PCA simplify ligand features in 2D; Tanimoto coefficient groups similar ligands for targeted screening.
  </figcaption>
</figure>
</span>


<!-- ---

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
### 5. Putting it all together


<span class='fragment ' >We perform active virtual screening on the inferred expert utility function.</span>




<span class='fragment ' >Our procedure respects expert preference (both hard and soft constraint) and probabilistic model to come up with a good candidate set.</span>




<span class='fragment ' >To search for poses required for objectives such as affinity, we accelerate the pose search by a neural search engine.</span>

 -->
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="3-active-virtual-screening-evaluation-metrics">3. Active Virtual Screening: Evaluation Metrics</h3>


<span class='fragment ' ><p><strong>Metrics for evaluation</strong></p>
</span>


<!-- 

<span class='fragment ' ><p><strong>Regret</strong></p>
</span>



<ul>
  <li class="fragment"><b>Definition</b>: Difference in affinity between the best possible ligand and the top ligand found by the model within the $top_k \%$.</li>
  <li class="fragment">$\text{Regret} = A_{\text{best}} - A_{\text{model}}$</li>
</ul> -->


<span class='fragment ' ><p><strong>Percent of Best Ligand Found</strong></p>
</span>


<ul>
  <li class="fragment"><b>Definition</b>: Percentage of screened ligands close in affinity to the best possible ligand. ($top_k \%$)</li>
</ul>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="3-active-virtual-screening-screening-results">3. Active Virtual Screening: Screening Results</h3>


<span class='fragment ' ><figure style="display: flex; flex-direction: column; align-items: center;">
  <div style="display: flex; justify-content: center; width: 100%; gap: 70px;">
      <img src="images/percent.png" style="width: 33%; max-width: 450px;">
      <img src="images/time1.png" style="width: 70%; max-width: 700px;">
  </div>
  <figcaption style="text-align: center; font-size: 20px; margin-top: 0px;">Efficiently identifying high-affinity ligands: Screening 5% of a 7000-ligand library</figcaption>
</figure>
</span>


</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="3-active-virtual-screening-next-steps">3. Active Virtual Screening: Next steps</h3>
<ul>
  <li class="fragment"> Run virtual screening on bigger library (100k, 1M) compounds</li>
</ul>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="outline-3">Outline</h3>
<ul>
<li><span style="opacity: 0.5;">Protein-ligand docking with Diffusion Models</span></li>
<li><span style="opacity: 0.5;">Active Virtual Screening</span></li>
<li>Incorporating Chemical Intuition</li>
</ul>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="4eliciting-chemical-intuition-overview">4.Eliciting Chemical Intuition: Overview</h3>
<p>

<span class='fragment ' >In drug discovery, selecting candidate ligands goes beyond targeting high-affinity molecules.</span>




<span class='fragment ' >Experts use their deep chemical intuition to balance competing properties such as synthesizability, solubility, and potential side effects.</span>




<span class='fragment ' >This approach ensures ligands are not only effective but also practical and safe for therapeutic use.</span>

</p>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="4eliciting-chemical-intuition">4.Eliciting Chemical Intuition</h3>
<p>Depending on the specific disease and protein, experts have <strong>intuition</strong> about characteristics of candidate ligands,


<span class='fragment ' >trading off various objectives such as synthesizability, affinity, solubility, and side effects.</span>

</p>


<span class='fragment ' ><div style="display: flex; justify-content: center; width: 100%; gap: -30px; margin-top: -100px;">
  <figure style="display: flex; flex-direction: column; align-items: center; width: 45%;">
    <img src="images/lig1.png" style="width: 100%;" alt="Aff: -10.11, PSA: 67.66">
    <figcaption style="text-align: left; font-size: 20px; margin-top: -50px;">Affinity: -10.11, Solubility: 67.66</figcaption>
  </figure>
  <figure style="display: flex; flex-direction: column; align-items: center; width: 45%;">
    <img src="images/lig2.png" style="width: 100%;" alt="Aff: -6.3, Solubility: 128.37">
    <figcaption style="text-align: left; font-size: 20px; margin-top: -50px;">Affinity: -6.3, Solubility: 128.37</figcaption>
  </figure>
</div>
</span>


</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="4eliciting-chemical-intuition-1">4.Eliciting Chemical Intuition</h3>
<p>These implicit expert knowledge, encoded as preferences over ligands, are valuable to elicit for effective virtual screening.


<span class='fragment ' >We can leverage toolkits from the field of machine learning from human preferences to tackle this challenge.</span>

</p>
<span class="fragment">
<table style="width: 90%; margin-top: 20px; border-collapse: collapse; text-align: center; font-size: 24px;">
  <tr>
    <th style="border: 1px solid #ddd; padding: 8px;">First ligand</th>
    <th style="border: 1px solid #ddd; padding: 8px;">Second ligand</th>
    <th style="border: 1px solid #ddd; padding: 8px;">Preference $(x_1 \succ x_2)$</th>
  </tr>
  <tr>
    <td style="border: 1px solid #ddd; padding: 8px;">[-7.81, 114.38, 0.51]</td>
    <td style="border: 1px solid #ddd; padding: 8px;">[-8.12, 116.28, 0.47]</td>
    <td style="border: 1px solid #ddd; padding: 8px;">0</td>
  </tr>
  <tr>
    <td style="border: 1px solid #ddd; padding: 8px;">[-10.45, 186.17, 0.29]</td>
    <td style="border: 1px solid #ddd; padding: 8px;">[-8.12, 116.28, 0.47]</td>
    <td style="border: 1px solid #ddd; padding: 8px;">1</td>
  </tr>
  <tr>
    <td style="border: 1px solid #ddd; padding: 8px;">[-6.18, 35.32, 0.83]</td>
    <td style="border: 1px solid #ddd; padding: 8px;">[-8.12, 116.28, 0.47]</td>
    <td style="border: 1px solid #ddd; padding: 8px;">0</td>
  </tr>
</table>
<p style="font-size: 24px; text-align: center; margin-top: 15px;">
  <em>Each ligand is represented by a set of features, such as affinity, polar surface area, QED drug-likeness score</em>
</p>
</span>
<!-- ---

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
### 4.Eliciting Chemical Intuition

Learning a preference model from binary preference data can be viewed as learning a classifier. 

  

<span class='fragment ' ><p>$$p(y \mid x_1, x_2; f) = \frac{e^{f(x_1)}}{e^{f(x_1)} + e^{f(x_2)}}$$</p>
</span>



  

<span class='fragment ' ><p>$$= \frac{1}{1 + e^{-[f(x_1)-f(x_2)]}}$$</p>
</span>



  

<span class='fragment ' ><p>$$= \sigma(f(x_1)-f(x_2))$$</p>
</span>





<span class='fragment ' >where $\sigma(\cdot)$ is the sigmoid function.</span>

 -->
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="4eliciting-chemical-intuition-2">4.Eliciting Chemical Intuition</h3>
<p>

<span class='fragment ' >The latent utility function $f$ can be modeled using various approaches.</span>




<span class='fragment ' >One popular choice is the <strong>Gaussian Process (GP)</strong>, a non-parametric Bayesian method that defines a distribution over possible functions.</span>

</p>
<!-- <p style="color: green;">Add a visualization for functions induced by different kernel here.</p> -->
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="4eliciting-chemical-intuition-3">4.Eliciting Chemical Intuition</h3>
<!-- 

<span class='fragment ' >By modeling utility with a Gaussian Process, we effectively capture both the uncertainty and the non-linear relationships inherent in expert preferences.</span>

 -->
<p>

<span class='fragment ' >Learning GP Classifier can be done with standard machine learning toolbox such as <code>scikit-learn</code>.</span>




<span class='fragment ' >For example, when the synthetic oracle is the Auckley function, we obtain 85% train and test accuracy.</span>

</p>


<span class='fragment ' ><img src="images/ackley.png" alt="ackley" style="display: block; margin: 0 auto; width: 45%;" class="fragment">
<p style="text-align: center; font-size: 20px">Synthetic Auckley function</p>
</span>


</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="4eliciting-chemical-intuition-process">4.Eliciting Chemical Intuition: Process</h3>
<p>Learning chemical intuition is done in a close-loop, where the computer interacts with the chemist in an active manner.


<span class='fragment ' >Starting with distribution over function $f$ condition on the current data, $p(f | D)$, our procedure includes 4 iterative steps:</span>

</p>


<span class='fragment ' ><strong>Step 1:</strong> Sample two candidate utility: $f_1 \sim p(f|D), f_2 \sim p(f|D)$</span>




<span class='fragment ' ><p><strong>Step 2:</strong> Find the best ligand under each utility function:</p>
<p>$$x_1 = \arg\max_{x \in \mathcal{L}} f_1(x), x_2 = \arg\max_{x \in \mathcal{L}} f_2 (x)$$</p>
</span>




<span class='fragment ' ><p><strong>Step 3:</strong> Present the two candidate ligands $x_1$ and $x_2$ to the expert to obtain preference $y$.</p>
</span>




<span class='fragment ' ><p><strong>Step 4:</strong> Update the model in the present of new data $\mathcal{D} \leftarrow \mathcal{D} \cup {(x_1, x_2, y)}$.</p>
</span>


</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="4eliciting-chemical-intuition-synthetic-results">4.Eliciting Chemical Intuition: Synthetic results</h3>


<span class='fragment ' ><img src="images/elicitation.png" alt="Active Virtual Screening Diagram" style="display: block; margin: 0 auto; width: 55%;" class="fragment">
<p style="text-align: center; font-size: 20px">Observed accuracy plot for high-dimensional data with objectives: QED, affinity, polar surface area, and molecular weight.</p>
</span>


</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="4eliciting-chemical-intuition-next-steps">4.Eliciting Chemical Intuition: Next Steps</h3>
<ul>
  <li class="fragment">We aim to collaborate with experts in the lab to understand their latent utility preferences via pairwise preference elicitation for virtual screening applications.</li>
</ul>


<span class='fragment ' ><img src="images/human.png" alt="Active Virtual Screening Diagram" style="display: block; margin: 0 auto; width: 65%;" class="fragment">
<p style="text-align: center; font-size: 24px">Incorporating chemists' intuition into the virtual screening loop.</p>
</span>


</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="5-conclusion">5. Conclusion</h3>
<ul>
  <li class="fragment">Enhance docking speed to achieve 8x faster performance than the current SOTA.</li>
  <li class="fragment">Conduct active virtual screening on a library of 7,000 compounds, achieving a success rate of ~25%.</li>
  <li class="fragment">Develop a synthetic function to test multi-objective preferences and identify top compounds.</li>
</ul>
</section>

<section data-noprocess data-shortcode-slide
      data-auto-animate="">
  
<h3 id="6-next-steps">6. Next steps</h3>
<ul> 
  <li class="fragment">Improve our virtual screening experiments so it's realistic (i.e., multi-objectives)</li> 
  <li class="fragment">Build on top of state-of-the-art models such as AlphaFold3</li> 
  <li class="fragment">Test on real data (e.g., from Glenn's lab)</li> 
</ul></section>

  


</div>
      

    </div>
<script type="text/javascript" src=/~sttruong/avs/reveal-hugo/object-assign.js></script>


<script src="/~sttruong/avs/reveal-js/dist/reveal.js"></script>


  <script type="text/javascript" src="/~sttruong/avs/reveal-js/plugin/markdown/markdown.js"></script>
  
  <script type="text/javascript" src="/~sttruong/avs/reveal-js/plugin/highlight/highlight.js"></script>
  
  <script type="text/javascript" src="/~sttruong/avs/reveal-js/plugin/zoom/zoom.js"></script>
  
  <script type="text/javascript" src="/~sttruong/avs/reveal-js/plugin/notes/notes.js"></script>
  
<script type="text/javascript">
  
  
  function camelize(map) {
    if (map) {
      Object.keys(map).forEach(function(k) {
        newK = k.replace(/(\_\w)/g, function(m) { return m[1].toUpperCase() });
        if (newK != k) {
          map[newK] = map[k];
          delete map[k];
        }
      });
    }
    return map;
  }

  var revealHugoDefaults = { center: true, controls: true, history: true, progress: true, transition: "slide" };
  var revealHugoSiteParams = {"custom_theme":"css/serif.css","enablesourcemap":true,"history":true,"margin":0.1,"slide_number":true};
  var revealHugoPageParams = {};

  var revealHugoPlugins = {
    
    plugins: [RevealMarkdown,RevealHighlight,RevealZoom,RevealNotes]
  };

  
  var options = Object.assign({},
    camelize(revealHugoDefaults),
    camelize(revealHugoSiteParams),
    camelize(revealHugoPageParams),
    camelize(revealHugoPlugins));

  Reveal.initialize(options);
</script>





  
  
    
  

  
  
    
  

  
  

  
  





<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
  

<script type="text/javascript" id="MathJax-script" async src="/~sttruong/avs/tex-svg_7522271970123696654.js"></script>

    
    
  </body>
</html>
